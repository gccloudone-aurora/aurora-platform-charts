global:
  helm: {}
    # Override all Helm applications to pull
    # their helm chart from the following
    # repository.
    #
    # You can override specific charts below
    # in the components section.
    # repository: https://myrepo.example.ca

  container: {}
    # Override all applications to pull
    # their container from the following
    # registry.
    #
    # You can override specific charts below
    # in the components section.
    # registry: docker.io

  namespace:
    helm:
      chart:
      targetRevision:
      repository:

  raw:
    helm:
      chart:
      targetRevision:
      repository:

  # azure or aws
  provider: azure

  # Cluster name for the Application targets.
  cluster: in-cluster

  # Which project to place applications in.
  project: aurora-core

  # Ingress Domain
  ingressDomain: example.ca

  # The Kubernetes API Server
  apiServerCidr: "192.0.2.10/32"

  # The Azure Metadata API
  azureMetadataApiCidr: "169.254.169.254/32"

  # Alert Manager
  alertManagerCidrs: ["192.0.2.10/32"]

  # Logging
  loggingCidrs: ["192.0.2.10/32"]

  # Creates local platform logging network policies on clusters running Loki
  # clusterHasLoki: false

  # Vault
  # vaultCidrs: ["192.0.2.10/32"]

  # Ingress Class Name
  # ingressClassName: ingress-istio-controller

  # The Azure subscription ID used for the cluster
  # subscriptionId: ""

  # The Azure tenant ID used for the cluster
  # tenantId: ""

  # Load Balancer Subnet Name for all Load Balancers
  # load_balancer_subnet_name: ""

  # child values import via dependencies
  imports:
    app:
      # Used in cases where a subchart's component depends on the aurora-app subchart being enabled
      enabled: false
    mgmt:
      # Used in cases where a subchart's component depends on the aurora-mgmt subchart being enabled
      enabled: false

# Role Based Access Control
rbac:
  # Groups and users that should be bound to the platform-admin role.
  # Note: if using AKS with AAD enabled, this is not necessary since admins
  #       will be defined in the configuration.
  platformAdmin:
    groups: []
    users: []
  # Configurations for the platform-operator-daily role.
  # An aggregated role which uses the
  # 'rbac.ssc-spc.gc.ca/aggregate-to-platform-operator-daily: "true"'
  # label as the selector.
  platformOperator:
    groups: []
    users: []
  # Configurations for the role given to SecOps.
  # A read-only role which uses the built-in Kubernetes `view` role.
  securityOperations:
    groups: []
    users: []

# Components
components:
  aadPodIdentity:
    enabled: true

    helm: {}
      # chart: aad-pod-identity
      # repository: https://raw.githubusercontent.com/Azure/aad-pod-identity/master/charts
      # targetRevision: 4.1.18

    imagePullSecrets: []
    image:
      # registry: mcr.microsoft.com/
      repository: oss/azure/aad-pod-identity
      # pullPolicy: IfNotPresent

    mic:
      image: mic
      # tag: v1.8.17

      replicas: 2
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        "node.ssc-spc.gc.ca/use": "general"
        "node.ssc-spc.gc.ca/purpose": "system"
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: mic

      podDisruptionBudget:
        minAvailable: 1

      priorityClassName: platform-cluster-medium

      logging: {}
        ## log level. Uses V logs (klog)
        # verbosity:
        # format:

    nmi:
      image: nmi
      # tag: v1.8.17

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux

      tolerations:
        # NMI is a daemonset.
        # An empty key with operator Exists matches all keys, values and effects which means this will tolerate everything.
        - operator: Exists
      affinity: {}
      priorityClassName: platform-cluster-critical

      logging: {}
        ## log level. Uses V logs (klog)
        # verbosity:
        # format:

  auroraController:
    enabled: true

    helm: {}
      # chart: aurora-controller
      # repository: https://gccloudone-aurora.github.io/aurora-platform-charts
      # targetRevision: 0.0.1

    imagePullSecrets:
      - name: aurora-controller-image-pull-secret

    image:
      # registry: ghcr.io
      repository: gccloudone-aurora/aurora-controller
      # tag: "main"
      # pullPolicy: IfNotPresent

    priorityClassName: platform-cluster-medium

    replicas: 2
    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: aurora-controller

    aurora:
      secretName: "aurora-image-pull-secret"
      # secretDockerConfigJson: ""

  awsEbsCsiDriver:
    enabled: true

    helm: {}
      # chart: aws-ebs-csi-driver
      # repository: https://kubernetes-sigs.github.io/aws-ebs-csi-driver
      # targetRevision: 2.47.0

    image:
      # registry: public.ecr.aws  
      repository: ebs-csi-driver/aws-ebs-csi-driver
      # tag: ""
      # pullPolicy: IfNotPresent

    controller:
      replicas: 2
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
        limits:
          memory: 256Mi
      nodeSelector: {}    

    node:
      resources:      
        requests:
          cpu: 10m
          memory: 40Mi
        limits:
          memory: 256Mi
      nodeSelector: {}

    # sidecars
    provisioner:
      image:
        # registry: public.ecr.aws  
        repository: csi-components/csi-provisioner
        # tag: "v5.3.0-eksbuild.3"
        # pullPolicy: IfNotPresent
      resources: {}

    attacher:
      image:
        # registry: public.ecr.aws  
        repository: csi-components/csi-attacher
        # tag: "v4.9.0-eksbuild.3"
        # pullPolicy: IfNotPresent
      resources: {}
    snapshotter:
      image:
        # registry: public.ecr.aws  
        repository: csi-components/csi-snapshotter
        # tag: "v8.3.0-eksbuild.1"
        # pullPolicy: IfNotPresent
      resources: {}
    resizer:
      image:
        # registry: public.ecr.aws  
        repository: csi-components/csi-resizer
        # tag: "v1.14.0-eksbuild.3"
        # pullPolicy: IfNotPresent
      resources: {}
    nodeDriverRegistrar:
      image:
        # registry: public.ecr.aws  
        repository: csi-components/csi-node-driver-registrar
        # tag: "v2.14.0-eksbuild.4"
        # pullPolicy: IfNotPresent
      resources: {}
    volumemodifier:
      image:
        # registry: public.ecr.aws  
        repository: ebs-csi-driver/volume-modifier-for-k8s
        # tag:  "v0.7.0"
        # pullPolicy: IfNotPresent
      resources: {}

  awsLoadbalancerController:
    enabled: true

    helm: {}
      # chart: aws-load-balancer-controller
      # repository: https://aws.github.io/eks-charts
      # targetRevision: 1.13.4

    imagePullSecrets: []
    image:
      # registry: public.ecr.aws
      repository: eks/aws-load-balancer-controller
      # tag: v2.13.4
      # pullPolicy: IfNotPresent

    replicas: 2
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi

    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    # affinity: {}

    priorityClassName: platform-cluster-medium

    enableCertManager: true
    enableServiceMinitor: true

  certManager:
    enabled: true

    helm: {}
      # chart: cert-manager
      # repository: https://charts.jetstack.io
      # targetRevision: v1.18.1

    imagePullSecrets: []
    image:
      # registry: quay.io
      repository: jetstack/cert-manager-controller
      # tag: "v1.18.1"
      # pullPolicy: IfNotPresent

    prometheus:
      enabled: true
      servicemonitor:
        enabled: true
        prometheusInstance: default
        targetPort: 9003
        path: /metrics
        interval: 60s
        scrapeTimeout: 30s
        labels: {}
        annotations: {}
        honorLabels: false
        endpointAdditionalProperties: {}

    replicas: 3
    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: controller

    webhook:
      image:
        # registry: quay.io
        repository: jetstack/cert-manager-webhook
        # tag: "v1.18.1"
        # pullPolicy: IfNotPresent

      replicas: 3
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: webhook

    cainjector:
      image:
        # registry: quay.io
        repository: jetstack/cert-manager-cainjector
        # tag: "v1.18.1"
        # pullPolicy: IfNotPresent

      replicas: 3
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: cainjector

    acmesolver:
      image:
        # registry: quay.io
        repository: jetstack/cert-manager-acmesolver
        # tag: "v1.18.1"
        # pullPolicy: IfNotPresent

    startupapicheck:
      image:
        # registry: quay.io
        repository: jetstack/cert-manager-startupapicheck
        # tag: "v1.18.1"
        # pullPolicy: IfNotPresent

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: startupapicheck

    dns01RecursiveNameservers: ""
    dns01RecursiveNameserversOnly: false

    podDnsConfig:
      nameservers: []

    azureWorkloadIdentity:
      enabled: true
      # clientId: ""

    serviceAccount:
      annotations: {}

    issuers:
      # email: ''
      # caBundle: ""

      dns01: {}
        # azureDNS:
        #   hostedZoneName:
        #   resourceGroupName:
        #   subscriptionId:

    priorityClassName: platform-cluster-medium

  cidrAllocator:
    enabled: true

    helm: {}
      # chart: cidr-allocator
      # repository: https://gccloudone-aurora.github.io/cidr-allocator
      # targetRevision: 0.0.1

    imagePullSecrets:
      - name: cidr-allocator-image-pull-secret

    image:
      # registry: ghcr.io
      repository: gccloudone-aurora/cidr-allocator
      # tag: "main"
      # pullPolicy: IfNotPresent

    priorityClassName: system-cluster-critical

    prometheus: {}

    addressPools: []
    staticAllocations: []

    replicas: 2
    resources:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "10m"
        memory: "64Mi"

    nodeSelector:
      kubernetes.io/os: "linux"
      node.ssc-spc.gc.ca/purpose: system

    tolerations:
      - operator: Exists

    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: cidr-allocator

    # secretDockerConfigJson: ""

  cilium:
    enabled: true

    helm: {}
      # chart: cilium
      # repository: https://helm.cilium.io
      # targetRevision: 1.14.19

    imagePullSecrets:
      - name: cilium-image-pull-secret

    ipamMode: "kubernetes"  

    enableIPv4Masquerade: false
    enableIPv6Masquerade: false

    bgpControlPlane:
      enabled: true

    image:
      # registry: docker.io
      repository: cilium/cilium
      tag: "v1.14.19"
      pullPolicy: IfNotPresent

    apiserver:
      image:
        # registry: docker.io
        repository: cilium/clustermesh-apiserver

      etcd:
        image:
          # registry: docker.io
          repository: coreos/etcd

    certgen:
      image:
        # registry: docker.io
        repository: cilium/certgen

    etcd:
      image:
        # registry: docker.io
        repository: cilium/cilium-etcd-operator

    hubble:
      relay:
        image:
          # registry: docker.io
          repository: cilium/hubble-relay

      ui:
        backend:
          image:
            # registry: docker.io
            repository: cilium/hubble-ui-backend

        frontend:
          image:
            # registry: docker.io
            repository: cilium/hubble-ui

    nodeinit:
      image:
        # registry: docker.io
        repository: cilium/startup-script

    operator:
      image:
        # registry: docker.io
        repository: cilium/operator

    preflight:
      image:
        # registry: docker.io
        repository: cilium/cilium

    priorityClassName: system-cluster-critical

    replicas: 2
    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - key: node.kubernetes.io/not-ready
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: cilium-operator

    # secretDockerConfigJson: ""

    ciliumBGPPeeringPolicy:
      nodeSelector:
        matchLabels:
          kubernetes.io/os: linux
      virtualRouters: []

  fluentOperator:
    enabled: true

    helm: {}
      # chart: fluent-operator
      # repository:  https://fluent.github.io/fluent-operator
      # targetRevision: 0.20.9

    containerRuntime: "containerd"
    imagePullSecrets: []

    operator:
      initContainer:
        image:
          # registry: docker.io
          repository: docker
          # tag: "20.10"
          # pullPolicy: IfNotPresent

      image:
        # registry: docker.io
        repository: kubesphere/fluent-operator
        # tag: "v2.4.0"
        # pullPolicy: IfNotPresent

      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 128Mi

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists

      priorityClassName: platform-cluster-critical

    fluentbit:
      crdsEnabled: true
      enabled: true

      image:
        repository: kubesphere/fluent-bit

      resources:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 128Mi

      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        - operator: Exists

      priorityClassName: platform-node-critical

      input:
        tail:
          enable: true
          refreshIntervalSeconds: 10
          memBufLimit: 100MB
          path: "/var/log/containers/*.log"
          skipLongLines: true
          readFromHead: false
          storageType: memory
          pauseOnChunksOverlimit: "off"
        systemd:
          enable: true
          systemdFilter:
            enable: true
            filters: []
          path: "/var/log/journal"
          includeKubelet: true
          stripUnderscores: "off"
          storageType: memory
          pauseOnChunksOverlimit: "off"

      output:
        # forwarding to fluentd is already implemented by default so no need to provide a forwarding config by default through values.
        # However, output **must** be set
        # source: https://github.com/fluent/fluent-operator/blob/9f5033150f5ca0eb4497edcf5ee5f5e7494e0e55/charts/fluent-operator/templates/fluentd-fluentd.yaml#L11
        stdout:
          enable: false

      filter:
        kubernetes:
          enable: true
        containerd:
          enable: true
        systemd:
          enable: true

    fluentd:
      crdsEnabled: true
      enabled: true

      image:
        # registry: docker.io
        repository: kubesphere/fluentd
        # tag: "v1.15.3"
        # pullPolicy: IfNotPresent

      # number of fluentd instances
      replicas: 1
      # the number of workers per fluentd instance
      workers: 2

      resources:
        limits:
          cpu: 1000m
          memory: 2Gi
        requests:
          cpu: 100m
          memory: 128Mi

      logLevel: info

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - operator: Exists

      priorityClassName: platform-node-critical

      forward:
        port: 24224

      watchedNamespaces: []

      output:
        loki:
          enable: true
          # url: ""
          # username: ""
          # password: ""
          buffer:
            enable: true
            type: "memory"
            disableChunkBackup: true
            flushMode: "interval"
            flushInterval: "1s"
            flushAtShutdown: true
            flushThreadCount: "8"
            # Max 4MB until https://github.com/grafana/loki/pull/11348
            chunkLimitSize: "4MB"
            totalLimitSize: "512MB"
            queueLimitLength: "16"
            retryType: "exponential_backoff"
            retryMaxInterval: "30s"
            retryExponentialBackoffBase: "30"
            overflowAction: "drop_oldest_chunk"

  gatekeeper:
    enabled: true

    helm: {}
      # chart: gatekeeper
      # repository: https://open-policy-agent.github.io/gatekeeper/charts
      # targetRevision:

    imagePullSecrets: []
    image:
      # registry: docker.io
      repository: openpolicyagent/gatekeeper
      crdRepository: openpolicyagent/gatekeeper-crds
      # tag: "v3.9.0"
      # pullPolicy: IfNotPresent

    priorityClassName: system-cluster-critical

    replicas: 3

    postInstall:
      image:
        # registry: docker.io
        repository: openpolicyagent/gatekeeper-crds
        # tag: "v3.9.0"
        # pullPolicy: IfNotPresent

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity: {}

      probeWebhook:
        image:
          # registry: docker.io
          repository: curlimages/curl
          # tag: 7.83.1
          # pullPolicy: IfNotPresent

    postUpgrade:
      image:
        # registry: docker.io
        repository: openpolicyagent/gatekeeper-crds
        # tag: "v3.9.0"
        # pullPolicy: IfNotPresent

      resources: {}
        # limits:
        #  cpu: ""
        #  memory: ""
        # requests:
        #  cpu: ""
        #  memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity: {}

    preUninstall:
      image:
        # registry: docker.io
        repository: openpolicyagent/gatekeeper-crds
        # tag: "v3.9.0"
        # pullPolicy: IfNotPresent

      resources: {}
        # limits:
        #  cpu: ""
        #  memory: ""
        # requests:
        #  cpu: ""
        #  memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity: {}

    audit:
      resources:
        limits:
          cpu: 500m
          memory: 2048Mi
        requests:
          cpu: 100m
          memory: 1024Mi

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity: {}

    controllerManager:
      exemptNamespaces: []
      resources:
        limits:
          cpu: 500m
          memory: 2048Mi
        requests:
          cpu: 100m
          memory: 1024Mi

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  control-plane: controller-manager
    mutations:
      repoURL: https://github.com/gccloudone-aurora/gatekeeper-mutations.git
      components:
      - "init-containers"
      - "istio-service-entries"
      - "solution-builders"
      # - "taints-and-tolerations"
      # targetRevision:

    crds:
      resources: {}
        # limits:
        #  cpu: ""
        #  memory: ""
        # requests:
        #  cpu: ""
        #  memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity: {}

    templates: {}
      # repository: https://github.com/gccloudone-aurora/gatekeeper-policies.git
      # path: .
      # targetRevision: main

    constraints:
      blockOperations:
        excludedNamespaces: []
        enforcementAction: "deny"
      k8sBlockWildcardIngress:
        labelSelector: {}
        excludedNamespaces: []
        enforcementAction: "deny"
      gatewayContainerAllowedImages:
        allowedRepos: []
        # - ghcr.io/
        # - docker.io/
        # - docker.elastic.co/
        # - mcr.microsoft.com/
        # - quay.io/
        # - registry.k8s.io/
        excludedNamespaces: []
        enforcementAction: "deny"
      systemContainerAllowedImages:
        allowedRepos: []
        # - ghcr.io/
        # - docker.io/
        # - docker.elastic.co/
        # - mcr.microsoft.com/
        # - quay.io/
        # - registry.k8s.io/
        excludedNamespaces: []
        enforcementAction: "deny"
      solutionContainerAllowedImages:
        allowedRepos: []
        # - ghcr.io/
        # - docker.io/
        # - docker.elastic.co/
        # - mcr.microsoft.com/
        # - quay.io/
        # - registry.k8s.io/
        excludedNamespaces: []
        enforcementAction: "deny"
      k8sPodDisruptionBudget:
        excludedNamespaces: []
        enforcementAction: "deny"
      k8sStorageClass:
        includeStorageClassesInMessage: true
        allowedStorageClasses: ["*", ""]
        excludedNamespaces: []
        enforcementAction: "deny"
      enforceCBR:
        excludedNamespaces: []
        enforcementAction: "warn"
        allowedRegex:
          - "^[0-9]{6}$"
        allowedValues: [""]
      gatewaysSolution:
        excludedNamespaces: []
        enforcementAction: "deny"
      gatewaysSystem:
        excludedNamespaces: []
        enforcementAction: "deny"
      restrictHostnames:
        excludedNamespaces: []
        exemptions: []
        enforcementAction: "deny"
      allowedServicePortName:
        allowedPrefixes: ["http-", "http2-", "https-", "tcp-", "tls-", "grpc-", "grpc-web-", "mongo-", "mysql-", "redis-"]
        excludedNamespaces: []
        enforcementAction: "deny"
      restrictPodAnnotations:
        excludedNamespaces: []
        enforcementAction: "deny"
        restrictedAnnotations:
          - key: galley.istio.io/analyze-suppress
          - key: inject.istio.io/templates
          - key: proxy.istio.io/config
          - key: sidecar.istio.io/inject
          - key: sidecar.istio.io/controlPlaneAuthPolicy
          - key: sidecar.istio.io/discoveryAddress
          - key: sidecar.istio.io/bootstrapOverride
          - key: traffic.sidecar.istio.io/excludeInboundPorts
          - key: traffic.istio.io/nodeSelector
          - key: sidecar.istio.io/proxyImage
          - key: sidecar.istio.io/proxyImageType
          - key: sidecar.istio.io/userVolume
          - key: sidecar.istio.io/userVolumeMount
          - key: status.sidecar.istio.io/port
          - key: istio.io/rev
        exemptAnnotations:
        - key: istio.io/rev
          value: "default"
      restrictPodLabels :
        excludedNamespaces: []
        enforcementAction: "deny"
        restrictedLabels:
        - galley.istio.io/analyze-suppress
        - networking.istio.io/gatewayPort
        - topology.istio.io/network
        - sidecar.istio.io/inject
        - topology.istio.io/subzone

  falco:
    enabled: true

    helm: {}
      # chart: falco
      # repository: https://falcosecurity.github.io/charts
      # targetRevision: 6.2.5

    resources: {}
    #   requests:
    #     cpu: 100m
    #     memory: 512Mi
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi

    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
    priorityClassName: system-cluster-critical

    falcoctl:
      artifact:
        follow:
          enabled: false
        install:
          enabled: true
          mounts:
            # volumeMounts specifically for the falcoctl containers
            volumeMounts: []
 
    images:
      falco:
        image:
          # registry: docker.io
          repository: falcosecurity/falco
          tag: "0.41.3"
          # pullPolicy: IfNotPresent

      falcoDriverLoader:
        image:
          # registry: docker.io
          repository: falcosecurity/falco-driver-loader
          tag: "0.41.3"
          # pullPolicy: IfNotPresent

      falcoctl:
        image:
          # registry: docker.io
          repository: falcosecurity/falcoctl
          tag: "0.11.2"
          # pullPolicy: IfNotPresent

      falcoSideKick:
        image:
          # registry: docker.io
          repository: falcosecurity/falcosidekick
          tag: "2.31.1"
          # pullPolicy: IfNotPresent
 
      k8sMetacollector:
        image:
          # registry: docker.io
          repository: falcosecurity/k8s-metacollector
          tag: "0.1.1"
          # pullPolicy: IfNotPresent

    mounts:
      # -- A list of volumes you want to add to the Falco pods.
      volumes: []
      # -- A list of volumes you want to add to the Falco pods.
      volumeMounts: []

  kubecost:
    enabled: false

    helm: {}
      # chart: cost-analyzer
      # repository: https://kubecost.github.io/cost-analyzer/
      # targetRevision:

    imagePullSecrets: []
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: cost-analyzer

    priorityClassName: platform-cluster-medium

    frontend:
      image:
        # registry: gcr.io
        repository: kubecost1/frontend
        # pullPolicy: Always

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

    costModel:
      image:
        # registry: gcr.io
        repository: kubecost1/cost-model
        # pullPolicy: Always

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

    networkCosts:
      image:
        # registry: gcr.io
        repository: kubecost1/kubecost-network-costs:v16.3
        # pullPolicy: Always

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: network-costs

    clusterController:
      image:
        # registry: gcr.io
        repository: kubecost1/cluster-controller:v0.6.0
        # pullPolicy: Always

    # token: abcde12345

    # azure:
    #   subscriptionId: abcde12345
    #   clientId: abcde12345
    #   clientPassword: abcde12345
    #   tenantId: abcde12345

    # cloudServiceKey: abcde12345
    # productKey: abcde12345
    # clusterProfile: # "development", "production" or "high-availability"

  kubernetesEventExporter:
    enabled: true

    helm: {}
      # chart: kubernetes-event-exporter
      # repository: https:///registry-1.docker.io/bitnamicharts
      # targetRevision: 3.1.2

    imagePullSecrets:
      - name: aurora-image-pull-secret
    image:
      # registry: docker.io
      repository: bitnamilegacy/kubernetes-event-exporter
      tag: 1.7.0-debian-12-r14
      pullPolicy: IfNotPresent

    pdb:
      create: true
      minAvailable: 1
      # maxUnavailable: ""
    priorityClassName: platform-node-critical

    replicas: 2
    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: kubernetes-event-exporter

    config:
      output:
        loki:
          # authorization: ""
          # url: ""

  ntp:
    enabled: true

    image:
      repository: busybox
      tag: latest

    imagePullSecrets:
      - name: aurora-image-pull-secret

    resources:
      limits:
        cpu: 10m
        memory: 40Mi
      requests:
        cpu: 10m
        memory: 40Mi

    pools:
      - server: time.nrc.ca
        options: "iburst maxsources 4"
      - server: time.chu.nrc.ca
        options: "iburst maxsources 4"

    tolerations:
      - operator: Exists

  podtracker:
    enabled: true

    helm: {}
      # chart: podtracker
      # repository: https://gccloudone-aurora.github.io/aurora-platform-charts
      # targetRevision: 1.1.1

    image:
      # registry: ghcr.io
      repository: gccloudone-aurora/podtracker
      # tag: "main"
      # pullPolicy: IfNotPresent

    imagePullSecrets: []

    priorityClassName: platform-cluster-medium

    leaderElectionEnabled: true
    replicaCount: 2

    webhooksEnabled: true

    podtrackerConfiguration: []

    securityContext:
      runAsNonRoot: true
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      runAsUser: 1000

    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 10m
        memory: 64Mi

    networkPolicies:
      enabled: true
      extraPolicies: []

    prometheus:
      enabled: true
      servicemonitor:
        enabled: true
        prometheusInstance: default
        targetPort: 9003
        path: /metrics
        interval: 60s
        scrapeTimeout: 30s
        labels: {}
        annotations: {}
        honorLabels: false
        endpointAdditionalProperties: {}

    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system

    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists

    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: podtracker

  prometheus:
    enabled: true

    helm: {}
      # chart: kube-prometheus-stack
      # repository: https://prometheus-community.github.io/helm-charts
      # targetRevision: 1.97.0

    imageRegistry: ""
    imagePullSecrets: []

    priorityClassName: platform-cluster-critical

    operator:
      image:
        # registry: quay.io
        repository: prometheus-operator/prometheus-operator
        # tag: "v0.62.0"
        # pullPolicy: IfNotPresent

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

      admissionWebhooks:
        image:
          # registry: k8s.gcr.io
          repository: ingress-nginx/kube-webhook-certgen
          # tag: "v1.3.0"
          # pullPolicy: IfNotPresent

        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""

      prometheusConfigReloader:
        image:
          # registry: quay.io
          repository: prometheus-operator/prometheus-config-reloader
          # tag: "v0.62.0"
          # pullPolicy: IfNotPresent

        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""

      thanos:
        image:
          # registry: k8s.gcr.io
          repository: thanos/thanos
          # tag: "v0.29.0"
          # pullPolicy: IfNotPresent

    alertmanager:
      enabled: false
      alertmanagerSpec:
        image:
          # registry: quay.io
          repository: prometheus/alertmanager
          # tag: "v0.24.0"
          # pullPolicy: IfNotPresent

        replicas: 1
        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""
        nodeSelector: {}
        tolerations: []
        affinity: {}

        storage: 2Gi

      config:
        severities:
          critical: "P1-Critical"
          major: "P2-Major"
          minor: "P3-Minor"

        environments:
          prod:
            matchers: []
          nonProd:
            matchers: []
          dev:
            matchers: []

        smtp:
          smarthost:
          from:
          auth_username:
          auth_password:

          sendAddresses:
            email:
              to:
              matchers: "severity =~ P2-Major|P1-Critical"
            # test_email:
            #   to:
            #   matchers: "severity =~ Testing-Major"

        deadMansSwitchURL:

        additionalConfig:
          receivers: []
          routes: []

    prometheus:

      netpol:
        allowFederation: true

      prometheusSpec:
        image:
          # registry: quay.io
          repository: prometheus/prometheus
          # tag: "v2.36.1"
          # pullPolicy: IfNotPresent

        replicas: 1
        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""
        nodeSelector:
          kubernetes.io/os: linux
          node.ssc-spc.gc.ca/purpose: system
        tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: prometheus

        storage: 80Gi

        additionalAlertManagerHosts: []

      rules:
        backup:
          enabled: false

    thanosRuler:
      thanosRulerSpec:
        image:
          # registry: quay.io
          repository: thanos/thanos
          # tag: "v0.29.0"
          # pullPolicy: IfNotPresent

        replicas: 1
        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""
        nodeSelector:
          kubernetes.io/os: linux
          node.ssc-spc.gc.ca/purpose: system
        tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: thanos

    grafana:
      image:
        # registry: docker.io
        repository: grafana/grafana
        # tag: "9.0.1"
        # pullPolicy: IfNotPresent

      replicas: 1
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: grafana

      # Mitigation for https://github.com/grafana/helm-charts/issues/1184
      deploymentStrategy:
        type: Recreate

      downloadDashboards:
        image:
          # registry: docker.io
          repository: kiwigrid/k8s-sidecar
          # tag: "1.19.2"
          # pullPolicy: IfNotPresent

        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""

      initChownData:
        image:
          # registry: docker.io
          repository: busybox
          # tag: "1.31.1"
          # pullPolicy: IfNotPresent

        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""

      sidecar:
        image:
          # registry: docker.io
          repository: kiwigrid/k8s-sidecar
          # tag: "1.19.2"
          # pullPolicy: IfNotPresent

        resources: {}
          # limits:
          #   cpu: ""
          #   memory: ""
          # requests:
          #   cpu: ""
          #   memory: ""

      # adminPassword: abcde12345
      # authUrl: "https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/authorize"
      # tokenUrl: "https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/token"
      allowedGroups: ""

      persistence:
        size: 20Gi

      # lokiDataSource:
      #   url: ""
      #   user: ""
      #   password: ""

    kubeStateMetrics:
      image:
        # registry: registry.k8s.io
        repository: kube-state-metrics/kube-state-metrics
        # tag: "v2.5.0"
        # pullPolicy: IfNotPresent

      replicas: 1
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: kube-state-metrics

    prometheusNodeExporter:
      image:
        # registry: quay.io
        repository: prometheus/node-exporter
        # tag: "v1.3.1"
        # pullPolicy: IfNotPresent

      replicas: 1
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: prometheus-node-exporter

    blackboxExporter:
      helm: {}
        # chart: prometheus-blackbox-exporter
        # repository: https://prometheus-community.github.io/helm-charts
        # targetRevision: 7.0.0
      image:
        # registry: docker.io
        repository: prom/blackbox-exporter
        # tag: "v0.23.0"
        # pullPolicy: IfNotPresent
      imagePullSecrets: []

      replicas: 1

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: prometheus-blackbox-exporter

      istioIngressGatewayProbes: []
        # - name:
        #   ipAddress:
      controlPlaneProbes: []
        # - name:
        #   url:
        #   bearerToken:

    additionalModules: {}
    additionalTargets: {}

    jiralert:
      helm: {}
        # chart: jiralert
        # repository: https://prometheus-community.github.io/helm-charts
        # targetRevision: 1.7.1

      image:
        # registry: docker.io
        # registry: quay.io
        repository: jiralert/jiralert-linux-amd64
        # tag: "0.0.1"
        # pullPolicy: IfNotPresent
      imagePullSecrets: []

      replicas: 1
      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: prometheus-jira-alert
      priorityClassName: platform-cluster-medium

      config:
        apiURL:
        project:
        user:
        password:

      receivers:
        critical:
          name: 'jiralert_critical'
          priority: Blocker
          components: ['Incoming Platform Alert']
        major:
          name: 'jiralert_major'
          priority: High
          components: ['Incoming Platform Alert']
        minor:
          name: 'jiralert_minor'
          priority: Medium
          components: ['Incoming Platform Alert']

    msteams:
      helm: {}
        # chart: prometheus-blackbox-exporter
        # repository: https://prometheus-community.github.io/helm-charts
        # targetRevision: 1.3.0
      image:
        # registry: quay.io/
        repository: prometheusmsteams/prometheus-msteams
        tag: "master"
        # pullPolicy: IfNotPresent
      imagePullSecrets: []

      replicas: 1

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: prometheus-msteams

      connectors: {}
      #  testing: ""
      #  devCritical: ""
      #  devMajor: ""
      #  devMinor: ""
      #  nonProdCritical: ""
      #  nonProdMajor: ""
      #  nonProdMinor: ""
      #  prodCritical: ""
      #  prodMajor: ""
      #  prodMinor: ""

  secretsStoreCSIDriver:
    enabled: false
    helm: {}
      # chart: secrets-store-csi-driver
      # repository: https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
      # targetRevision: 1.5.4
  
    images:
      driver:
        image:
          # registry: registry.k8s.io
          repository: csi-secrets-store/driver
          # tag: "v1.5.4"
          # pullPolicy: IfNotPresent

      crds:
        image:
          # registry: registry.k8s.io
          repository: csi-secrets-store/driver-crds
          # tag: "v1.5.4"
          # pullPolicy: IfNotPresent

      registrar:
        image:
          # registry: registry.k8s.io
          repository: sig-storage/csi-node-driver-registrar
          tag: v2.13.0

    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane

    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    
    priorityClassName: platform-cluster-medium

  trivy:
    enabled: true
    helm: {}
      # chart: trivy-operator
      # repository: https://aquasecurity.github.io/helm-charts
      # targetRevision: 0.31.0

    imagePullSecrets: []
    image:
      # registry: docker.io
      repository: aquasec/trivy-operator
      tag: "0.29.0"
      pullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 100m
        memory: 100M
      limits:
        cpu: 500m
        memory: 500M
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: trivy-operator
    priorityClassName: platform-cluster-medium
    
    targetWorkloads: "pod,replicaset,replicationcontroller,statefulset,daemonset,cronjob,job"
    excludeNamespaces: "*system"

    operator:
      # enable builtin server mode
      builtInTrivyServer: true
      # -- the flag to enable vulnerability scanner
      vulnerabilityScannerEnabled: true
      # -- configAuditScannerEnabled the flag to enable configuration audit scanner
      configAuditScannerEnabled: false
      # -- rbacAssessmentScannerEnabled the flag to enable rbac assessment scanner
      rbacAssessmentScannerEnabled: false
      # -- infraAssessmentScannerEnabled the flag to enable infra assessment scanner
      infraAssessmentScannerEnabled: false
      # -- exposedSecretScannerEnabled the flag to enable exposed secret scanner
      exposedSecretScannerEnabled: false
      
    severity: "HIGH,CRITICAL"
    server:
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1Gi
      extraServerVolumes:
        volumeMounts: 
         - name: trust-manager-propagated-custom-ca
           mountPath: /etc/ssl/certs/trust-manager-propagated-custom-ca.crt
           subPath: ca-certificates.crt
           readOnly: true
        volumes: 
         - name: trust-manager-propagated-custom-ca
           configMap:
             name: trust-manager-propagated-custom-ca

  tetragon:
    enabled: false

    helm: {}
      # chart: tetragon
      # repository: https://helm.cilium.io
      # targetRevision: 1.4.0

    imagePullSecrets: []

    image:
      # registry: quay.io
      repository: cilium/tetragon
      tag: "v1.4.0"
      pullPolicy: IfNotPresent

    operator:
      image:
        # registry: quay.io
        repository: cilium/tetragon-operator
        tag: "v1.4.0"
        pullPolicy: IfNotPresent

      replicas: 2

      priorityClassName: system-cluster-critical

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: tetragon-operator

    export:
      image:
        # registry: quay.io
        repository: cilium/hubble-export-stdout
        tag: "v1.1.0"
        pullPolicy: IfNotPresent

  trustManager:
    enabled: true

    helm: {}
      # chart: trust-manager
      # repository: https://charts.jetstack.io
      # targetRevision: v0.19.0

    imagePullSecrets: []
    image:
      # registry: quay.io
      repository: jetstack/trust-manager
      # tag: "v0.19.0"
      # pullPolicy: IfNotPresent

    replicas: 1
    resources: {}
      # limits:
      #   cpu: ""
      #   memory: ""
      # requests:
      #   cpu: ""
      #   memory: ""
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: trust-manager

    bundle:
      customCA: ""

    defaultPackage:
      image:
        # registry: quay.io
        repository: jetstack/trust-pkg-debian-bookworm
        tag: "20230311-deb12u1.0"
        # pullPolicy: IfNotPresent

      resources: {}
        # limits:
        #   cpu: ""
        #   memory: ""
        # requests:
        #   cpu: ""
        #   memory: ""

    priorityClassName: platform-cluster-medium

  vaultAgent:
    enabled: false

    helm: {}
      # chart: vault
      # repository: https://helm.releases.hashicorp.com
      # targetRevision: 0.20.1

    imagePullSecrets: []

    injector:
      image:
        # registry: docker.io
        repository: hashicorp/vault-k8s
        # tag: "1.0.0"
        # pullPolicy: IfNotPresent

      replicas: 3
      resources: {}
        # limits:
        #   cpu: 250m
        #   memory: 256Mi
        # requests:
        #   cpu: 250m
        #   memory: 256Mi
      nodeSelector:
        kubernetes.io/os: linux
        node.ssc-spc.gc.ca/purpose: system
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/instance: vault-agent

      agentImage:
        # registry: docker.io
        repository: hashicorp/vault
        # tag: "1.11.4"

      agentDefaults: {}
        # cpuLimit: "500m"
        # cpuRequest: "250m"
        # memLimit: "128Mi"
        # memRequest: "64Mi"

      annotations:
        istioInject:
          disable: true

      # externalVaultAddr: ""
      # authPath: ""

    priorityClassName: platform-cluster-critical

  velero:
    enabled: true

    helm: {}
      # chart: velero
      # repository: https://vmware-tanzu.github.io/helm-charts
      # targetRevision: 3.1.4

    imagePullSecrets: []
    image:
      # registry: docker.io
      repository: velero/velero
      # tag: "v1.10.2"
      # pullPolicy: IfNotPresent

    resources:
      requests:
        cpu: '1'
        memory: 512Mi
      limits:
        cpu: '1'
        memory: 1Gi
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: velero
    
    azureWorkloadIdentity:
      enabled: true
      # clientId: ""
    
    serviceAccount:
      server:
        annotations: {}

    backupStorage: {}
      # bucket:
      # resourceGroupName:
      # storageAccountName:
      # subscriptionId:

    volumeSnapshot: {}
      # resourceGroupName:

    plugins:
      azure:
        image:
          # registry: docker.io
          repository: velero/velero-plugin-for-microsoft-azure
          tag: "v1.13.1"
      aws:
        image:
          # registry: docker.io
          repository: velero/velero-plugin-for-aws
          tag: "v1.12.1"      

    kubectl:
      image:
        # registry: docker.io
        repository: bitnamilegacy/kubectl
        # tag: "1.16.15"

    priorityClassName: platform-cluster-medium

  kubebench:
    enabled: true
    # cronjob:
      # schedule: "0 0 1 * *"

    imagePullSecrets: []
    image:
      # registry: docker.io
      repository: aquasec/kube-bench
      tag: "v0.8.0"
      pullPolicy: IfNotPresent

    resources:
      requests:
        cpu: '1'
        memory: 512Mi
      limits:
        cpu: '1'
        memory: 1Gi
    nodeSelector:
      kubernetes.io/os: linux
      node.ssc-spc.gc.ca/purpose: system
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists

    cronjob:
      schedule: "0 0 1 * *"
      command: []

    extraLabels: {}
    podLabels: {}
    concurrencyPolicy: Forbid
    
    volumes:
      - name: var-lib-kubelet
        hostPath:
          path: "/var/lib/kubelet"
      - name: etc-systemd
        hostPath:
          path: "/etc/systemd"
      - name: etc-kubernetes
        hostPath:
          path: "/etc/kubernetes"
    volumeMounts:
      - name: var-lib-kubelet
        mountPath: /var/lib/kubelet
        readOnly: true
      - name: etc-systemd
        mountPath: /etc/systemd
        readOnly: true
      - name: etc-kubernetes
        mountPath: /etc/kubernetes
        readOnly: true

    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: kube-bench
    serviceAccount:
      annotations: {}